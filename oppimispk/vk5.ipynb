{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sustainable-fairy",
   "metadata": {},
   "source": [
    "# Oppimispäiväkirja - Viikko 5\n",
    "\n",
    "NLP on jo jonkun aikaa kiinnostanut itseäni kovasti, ja siihen olisi kiva perehtyä enemmänkin. Tämä vierailuluento tarjosi siihen hyvän aloituksen, ja vierailuluento oli mielestäni kaikin puolin todella onnistunut. Itselle on myös aina ollut helpompi opetella asioita niin, että ne tekee kerran kunnon ohjeistuksella, ja sen jälkeen kokeilee itse. Tämän vuoksi tämä konkreettinen demo sopi itselle todella hyvin. Jostain syystä en ole itse ikinä oppinut lähteä vain kokeilemaan asioita omin päin, vaikka sitäkin taitoa pitäisi varmaan alkaa kehittämään.\n",
    "\n",
    "Hukkasanoista on aikaisemmillakin luennoilla ollut puhetta, mutta nyt pääsi näkemään niiden käsittelyä käytännössä ja sai niiden suodattamisesta hyvän esimerkin sekä hyviä vinkkejä näiden kanssa toimimiseen. Tämä lisäksi oppi myös, että stopword = hukkasana. Hieman jäi vielä mietityttään tuo, että miten sana määritellään hukkasanaksi. Voiko jonkun hukkasanan poistaminen kuitenkin merkittävästi muuttaa lauseen merkitystä? Luultavasti ei, ja toisaalta esikäsittelyn voi aina tehdä uusiksi, jos hukkasanalista ei ole tarpeeksi hyvä omaan tarkoitukseen.\n",
    "\n",
    "Kuten luennolla todettiinkin, loppujen lopuksi datan siivouksessa päätös on tutkijalla itsellään, mitä datasta siivoo pois ja mitä ei. Tämä ei liity pelkästään NLP tapauksiin, vaan datatieteeseen yleensä. Toisaalta tämä valinnanvapaus on jollain tavalla pelottava ajatus, toisaalta helpottaa tietää että oikeita vastauksia ei tässä(kään?) tapauksessa ole. Yrityksen ja erehdyksen kautta pääsee varmasti tässäkin eteenpäin ja pitkälle.\n",
    "\n",
    "Luennolla nousi esille myös suomen kielen tuomat haasteet NLP yhteydessä. Olen aikaisemminkin kuullut, että suomen kielellä NLP on huomattavasti hankalampaa kielen erityispiirteiden vuoksi. Nopealla googletuksella löysin monta päättötyötä tähän liittyen, ja tämä onkin varmasti asia, mitä tutkitaan ja kehitetään jatkuvasti. Olen aikaisemmin luullut, että suomenkielinen NLP olisi vielä hankalampaa, mutta vierailuluennon perusteella se on edelleen täysin mahdollista ja vielä suhteellisen helppoa. \n",
    "\n",
    "Koodidemon haluan tehdä tällä viikolla NLP ja hukkasanoihin liittyen, koska datan esikäsittelyyn ei voi koskaan perehtyä liikaa. Etsiessäni dataa Kagglesta koodiesimerkkiä varten löysin monta todella hyvää koodiesimerkkiä NLP liittyen. Tässä taas huomasi ja muisti sen, kuinka paljon valmista koodia on saatavilla, ja kaikkea (tai oikeastaan mitään) ei tarvitse osata tehdä itse ulkomuistista. Noita koodeja voi lueskella sitten vaikka iltasaduiksi.\n",
    "\n",
    "### Tärkeimmät opit\n",
    "1. Tärkeintä on (tässäkin tapauksessa) NLP aineiston esikäsittely ja piirteiden erottaminen.\n",
    "2. NLP on yleensä vain yksi ulottuvuus jossain koneoppimismallissa.\n",
    "3. Uusia termejä (korpus) ja uusia kirjastoja ja palveluita (voikko, nltk, fasttext, google colab)\n",
    "4. Jos malli on heikko, voi palata takaisin esikäsittelyyn. \n",
    "5. Mallin overfittaaminen eli mallin erikoistuminen opetusdataan.\n",
    "6. Kirjastojen käyttö yleensä tehokkaampaa, kuin asioiden koodaus itse. Tärkeä taito pystyä ottamaan uusia kirjastoja käyttöön!\n",
    "\n",
    "### Risut ja ruusut luentoviikolle\n",
    "+ Vierailuluento oli todella onnistunut käytännönläheisyytensä vuoksi. Konkreettinen esimerkki mihin sai itse osallistua oli todella hyvä, eli teorian ja käytännön suhde oli onnistunut!\n",
    "+ Vaikka pakolliset yritysesittelyt on aina pakko pitää, niin se oli tällä kertaa tarpeeksi tiivis, ei turhia lukuja jne. Iso peukku siis Solitan pojille tästä!\n",
    "+ Tykkäsin myös luennon aikana esitetyistä kysymyksistä, johon sai pohtia vastauksia, vaikka ei päässyt livenä osallistumaan kyseiselle virailuluennolle. \n",
    "\n",
    "### Kehitysehdotukset \n",
    "- Ehdottomasti vastaavia vierailuluentoja jatkossakin!!\n",
    "\n",
    "## Linkit ja lähteet:\n",
    "- Text Preprocessing in Python: https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n",
    "- Koodiesimerkki: https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection\n",
    "- Koodiesimerkki: https://www.kaggle.com/mayurjain/sarcasm-detection-using-cuml-and-sklearn\n",
    "\n",
    "*(Katsoin vierailuluennon tallenteena. Lähteenä käytetty vierailuluennon luentomuistiota ja koodeja. Datasetti haettu Kagglesta.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prescribed-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in c:\\users\\jenna.rajala\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.4.4-cp37-cp37m-win_amd64.whl (269 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.0.0-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jenna.rajala\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click->nltk) (0.4.3)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.0.0 nltk-3.6.2 regex-2021.4.4 tqdm-4.60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jenna.rajala\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "painted-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koodiesimerkki - vk5\n",
    "\n",
    "# Koodiesimerkki liittyy tällä viikolla NLP:hen vierailuluennosta inspiroituneena.\n",
    "# Tämän koodi kuvaa hukkasanojen poiston datasta.\n",
    "\n",
    "# Haetaan tarvittavat kirjastot\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation as pnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "varying-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luetaan json-tiedosto dataframeen.\n",
    "df = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "educational-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Määritellään hukkasanoihin myös välimerkit.\n",
    "stopwords = set(sw.words('english'))\n",
    "punctuations = list(pnc)\n",
    "stopwords.update(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reduced-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "harmful-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luodaan uusi funktio tekstin käsittelyä varten.\n",
    "def text_processing(x):\n",
    "    text = []\n",
    "    for i in x.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            i = re.sub('[^a-zA-Z0-9]', '', i)\n",
    "            text.append(i.strip())\n",
    "            \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "general-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajetaan funktio headline sarakkeeseen.\n",
    "df['headline'] = df.headline.apply(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sized-alexander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    thirtysomething scientists unveil doomsday clo...\n",
       "1    dem rep totally nails congress falling short g...\n",
       "2          eat veggies 9 deliciously different recipes\n",
       "3         inclement weather prevents liar getting work\n",
       "4    mother comes pretty close using word streaming...\n",
       "5                                    white inheritance\n",
       "6                        5 ways file taxes less stress\n",
       "7    richard bransons globalwarming donation nearly...\n",
       "8    shadow government getting large meet marriott ...\n",
       "9                           lots parents know scenario\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Katsotaan, että hukkasanat on poistettu.\n",
    "df['headline'][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
